{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusive Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_data(data, title_str='Data'):\n",
    "    # function for scattering data\n",
    "\n",
    "    # create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Scatter data points in 2-dimensional space\n",
    "    ax.scatter(data[:,0], data[:,1], label='data', c='blue', alpha=1)\n",
    "    # set a title and labels\n",
    "    ax.set_title(title_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_vector_field(points, vectors, title_str=\"vector field\", lim=None, scale = 0.1):\n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "    x = points[:,0]\n",
    "    y = points[:,1]\n",
    "    x_v = vectors[:,0]\n",
    "    y_v = vectors[:,1]\n",
    "\n",
    "    plt.quiver(x, y, x_v, y_v, color=\"blue\", angles='xy', scale_units='xy', headwidth=2, scale=scale, alpha=.7)\n",
    "\n",
    "    if lim is None:\n",
    "        x_min = min(x.min(), (x + x_v).min())\n",
    "        x_max = max(x.max(), (x + x_v).max())\n",
    "        y_min = min(y.min(), (y + y_v).min())\n",
    "        y_max = max(y.max(), (y + y_v).max())\n",
    "\n",
    "        padding = .3\n",
    "        plt.xlim(x_min - padding, x_max + padding)\n",
    "        plt.ylim(y_min - padding, y_max + padding)\n",
    "    else:\n",
    "        plt.xlim(-lim, lim)\n",
    "        plt.ylim(-lim, lim)\n",
    "\n",
    "    ax.set_title(title_str)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t 값에 따라 layer connect가 달라지도록 Neural net 설계\n",
    "class MaskedLinear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, mask):\n",
    "        super(MaskedLinear, self).__init__(in_features, out_features)\n",
    "        self.mask = mask\n",
    "    \n",
    "    def forward(self, input):\n",
    "        masked_w = self.weight * self.mask\n",
    "        return nn.functional.linear(input, masked_w, self.bias)\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(1, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 1024 * 2),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(64, 2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, t):\n",
    "        # t_tensor = torch.ones_like(self.data, dtype=torch.float) * t\n",
    "        # data_with_t = torch.cat((self.data, t_tensor), dim=1)\n",
    "        # flattened_data_t = data_with_t.view(-1)\n",
    "        t = torch.tensor([t], dtype=torch.float)\n",
    "        t = t.view(-1, 1)\n",
    "        out = self.layers(t)\n",
    "        out = out.view(1024, 2)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class diffuse(nn.Module):\n",
    "    def __init__(self, n_steps=200, min_beta=10 ** -4, max_beta=0.02, device=None):\n",
    "        super(diffuse, self).__init__()\n",
    "        self.n_steps = n_steps\n",
    "        self.device = device\n",
    "        self.betas = torch.linspace(min_beta, max_beta, n_steps).to(\n",
    "            device)\n",
    "        self.alphas = 1 - self.betas\n",
    "        self.alpha_bars = torch.tensor([torch.prod(self.alphas[:i + 1]) for i in range(len(self.alphas))]).to(device)\n",
    "\n",
    "    def forward(self, data, t, eta=None):\n",
    "        # # x_0 -> x_t\n",
    "        # n, d = data.shape\n",
    "        # a_bar = self.alpha_bars[t-1]\n",
    "\n",
    "        # if eta is None:\n",
    "        #     eta = torch.randn(n, d).to(self.device)\n",
    "\n",
    "        # noisy = a_bar.sqrt().view(-1,1) * data + (1 - a_bar).sqrt().view(-1,1) * eta\n",
    "\n",
    "        # x_t -> x_t+1\n",
    "        data = data.to(self.device)\n",
    "        n, d = data.shape\n",
    "        beta = self.betas[t-1].to(self.device)\n",
    "\n",
    "        if eta is None:\n",
    "            eta = torch.randn(n, d).to(self.device)\n",
    "\n",
    "        noisy = (1-beta).sqrt().view(-1, 1) * data + beta.sqrt().view(-1, 1) * eta\n",
    "        return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vector_field(vectors):\n",
    "    # print(vectors)\n",
    "    norms = torch.norm(vectors, p=2, dim=1, keepdim=True)\n",
    "    \n",
    "    threshold = math.floor(math.log10(norms.max()))\n",
    "    # print(threshold)\n",
    "    # print(norms)\n",
    "    for i, norm in enumerate(norms):\n",
    "        if norm <= 10**threshold/2:\n",
    "            norms[i] = 0.\n",
    "    \n",
    "    mask = (norms != 0).expand_as(vectors)\n",
    "    norms = norms.expand_as(vectors)\n",
    "    normalized_v = torch.zeros_like(vectors)\n",
    "    normalized_v[mask] = vectors[mask] / norms[mask]\n",
    "\n",
    "    return normalized_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_t에서의 velocity vector data 생성 (normalized vectors)\n",
    "def make_vectors(diffuse, data, t):\n",
    "    data = data.to(device)\n",
    "    eta = torch.randn_like(data).to(device)\n",
    "\n",
    "    noisy_data = diffuse(data, t, eta).to(device)\n",
    "    v = noisy_data-data\n",
    "\n",
    "    return noisy_data, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vector_field(grid_points, data, vectors, radius=.3):\n",
    "    grid_points = grid_points.cpu()\n",
    "    data = data.cpu()\n",
    "\n",
    "    vector_field = torch.zeros_like(grid_points)\n",
    "\n",
    "    for i, point in enumerate(grid_points):\n",
    "        distances = torch.norm(data-point, dim=1)\n",
    "        mask = (distances <= radius)\n",
    "        neighbor_vs = vectors[mask]\n",
    "\n",
    "        if neighbor_vs.size(0) > 0:\n",
    "            vector_field[i] = neighbor_vs.mean(dim=0)\n",
    "    \n",
    "    # vector_field = normalize_vector_field(vector_field)\n",
    "\n",
    "    return vector_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model_1(epochs, grid_points, data, diffuse, m, device):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(m.parameters(), lr=0.0001)\n",
    "    # losses_t = torch.zeros(epochs, device=device)\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        _,v = make_vectors(diffuse, data, 1)\n",
    "        vf = make_vector_field(grid_points, data, v)\n",
    "        vf = normalize_vector_field(vf)\n",
    "        \n",
    "        vf_pred = m(1)\n",
    "\n",
    "        # print(vf.shape)\n",
    "        # print(vf_pred.shape)\n",
    "\n",
    "        mask_zero = (vf == 0).all(dim=1)\n",
    "        zero_loss = (vf_pred[mask_zero] ** 2).sum()\n",
    "        loss = criterion(vf_pred.to(device), vf.to(device)) + zero_loss * 5\n",
    "        # loss = criterion(vf_pred.to(device), vf.to(device))\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"epoch: {}, loss: {}\".format(epoch, loss.item()))\n",
    "\n",
    "        # losses_t[epoch] = loss.item()\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model_2(epochs, grid_points, data, diffuse, m, device):\n",
    "    all_losses = torch.zeros(diffuse.n_steps, 1, device=device, dtype=torch.float32)\n",
    "    for t in range(1, diffuse.n_steps+1):\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.SGD(m.parameters(), lr=0.0001)\n",
    "        # losses_t = torch.zeros(epochs, device=device)\n",
    "        loss_t = 0\n",
    "        x = data.to(device)\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x,v = make_vectors(diffuse, x, t)\n",
    "            vf = make_vector_field(grid_points, data, v)\n",
    "            \n",
    "            vf_pred = m(t).to(device)\n",
    "\n",
    "            mask_zero = (vf == 0).all(dim=1)\n",
    "            zero_loss = (vf_pred[mask_zero] ** 2).sum()\n",
    "            loss = criterion(vf_pred.to(device), vf.to(device)) + zero_loss*3\n",
    "\n",
    "            if epoch == epochs-1:\n",
    "                print(\"t: {}, epoch: {}, loss: {}\".format(t, epoch, loss.item()))\n",
    "\n",
    "            # losses_t[epoch] = loss.item()\n",
    "            loss_t = loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "        all_losses[t-1,0] = loss_t\n",
    "    \n",
    "    return all_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model_3(epochs, grid_points, data, diffuse, m, device):\n",
    "    final_loss = 0\n",
    "    for epoch in range(epochs):\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.SGD(m.parameters(), lr=0.0001)\n",
    "        # losses_t = torch.zeros(epochs, device=device)\n",
    "        x = data.to(device)\n",
    "        for t in range(1, diffuse.n_steps+1):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x,v = make_vectors(diffuse, x, t)\n",
    "            vf = make_vector_field(grid_points, x, v)\n",
    "            \n",
    "            vf_pred = m(t).to(device)\n",
    "\n",
    "            mask_zero = (vf == 0).all(dim=1)\n",
    "            zero_loss = (vf_pred[mask_zero] ** 2).sum()\n",
    "            loss = criterion(vf_pred.to(device), vf.to(device)) + zero_loss*5\n",
    "            # loss = criterion(vf_pred.to(device), vf.to(device))\n",
    "            final_loss = loss.item()\n",
    "            if epoch %100 == 0 and t == diffuse.n_steps:\n",
    "                print(\"t: {}, epoch: {}, loss: {}\".format(t, epoch, loss.item()))\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "    return final_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model_4(epochs, grid_points, data, diffuse, models, device):\n",
    "    final_loss = 0\n",
    "    criterions = []\n",
    "    optimizers = []\n",
    "\n",
    "    for t in range(n_steps):\n",
    "        criterions.append(nn.MSELoss()) \n",
    "        optimizers.append(optim.SGD(models[t].parameters(), lr=0.0001*(t+1)))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # losses_t = torch.zeros(epochs, device=device)\n",
    "        x = data.to(device)\n",
    "        for t in range(1, diffuse.n_steps+1):\n",
    "            m = models[t-1]\n",
    "            criterion = criterions[t-1]\n",
    "            optimizer = optimizers[t-1]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x,v = make_vectors(diffuse, x, t)\n",
    "            vf = make_vector_field(grid_points, x, v)\n",
    "            \n",
    "            vf_pred = m(t).to(device)\n",
    "\n",
    "            mask_zero = (vf == 0).all(dim=1)\n",
    "            zero_loss = (vf_pred[mask_zero] ** 2).sum()\n",
    "            loss = criterion(vf_pred.to(device), vf.to(device)) + zero_loss*(5/t)\n",
    "            # loss = criterion(vf_pred.to(device), vf.to(device))\n",
    "            final_loss = loss.item()\n",
    "            if epoch %100 == 0 and t == diffuse.n_steps:\n",
    "                print(\"t: {}, epoch: {}, loss: {}\".format(t, epoch, loss.item()))\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "    return final_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining diffuse\n",
    "n_steps, min_beta, max_beta = 10, 10 ** -4, 0.02\n",
    "input_dim=2\n",
    "output_dim=2\n",
    "\n",
    "d = diffuse(n_steps=n_steps, min_beta=min_beta, max_beta=max_beta, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 격자 점 생성\n",
    "x = torch.linspace(-5, 5, 32)\n",
    "y = torch.linspace(-5, 5, 32)\n",
    "X, Y = torch.meshgrid(x, y)\n",
    "grid_points = torch.stack([X.flatten(), Y.flatten()], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian data (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a Gaussian data\n",
    "dim = 2\n",
    "datanum = 500\n",
    "mean = np.array([0, 0])\n",
    "cov = np.array([[.1,.01],[.01,.1]])\n",
    "\n",
    "data1 = np.random.multivariate_normal(mean, cov, datanum)\n",
    "data1 = torch.from_numpy(data1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_data(data1.cpu(), title_str='Data')\n",
    "lim = 8\n",
    "plt.xlim(-lim, lim)\n",
    "plt.ylim(-lim, lim)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_data(grid_points.cpu(), title_str='Grid_points')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _,v = make_vectors(d, data1, 1)\n",
    "# vf = make_vector_field(grid_points, data1, v)\n",
    "# vf = normalize_vector_field(vf)\n",
    "# draw_vector_field(grid_points.cpu(), vf.cpu(), title_str=\"predicted vector field at t={}\".format(1), scale=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t = 1 에서만 Training - training_model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model\n",
    "m1 = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 - training_model_1\n",
    "epochs = 500\n",
    "\n",
    "losses = training_model_1(epochs, grid_points, data1, d, m1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n",
    "print(\"Final loss: {}\".format( losses[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffused data (from t=0 to t=9) (비교용)\n",
    "eta = torch.randn_like(data1).to(device)\n",
    "x_curr = data1.to(device)\n",
    "x_curr, v = make_vectors(d, x_curr, 1)\n",
    "\n",
    "vf = make_vector_field(grid_points, data1, v)\n",
    "\n",
    "vf = normalize_vector_field(vf)\n",
    "\n",
    "\n",
    "draw_vector_field(grid_points.cpu(), vf.cpu(), title_str=\"diffused data - avg. vector field\", scale=5)\n",
    "# draw_vector_field(data1.cpu(), v.cpu(), title_str=\"diffused data - avg. vector field\")\n",
    "i = 0\n",
    "for v in vf:\n",
    "    if v.norm() > 0:\n",
    "        i += 1\n",
    "    \n",
    "print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MyModel prediction - training_model_1 결과\n",
    "with torch.no_grad():\n",
    "    outputs = m1(1)\n",
    "\n",
    "    # draw_vector_field(grid_points.cpu(), outputs.cpu(), title_str=\"predicted vector field at t={}\".format(1), scale=0.1)\n",
    "\n",
    "    norms = torch.norm(outputs, p=2, dim=1, keepdim=True)\n",
    "    print(\"outptus max: \", norms.max().item())\n",
    "    print(\"outputs min: \", norms.min().item())\n",
    "    print(\"outputs avg: \", norms.mean().item())\n",
    "    \n",
    "    normalized_out = normalize_vector_field(outputs)\n",
    "    draw_vector_field(grid_points.cpu(), normalized_out.cpu(), lim=5.5, title_str=\"predicted vector field at t={}\".format(1), scale=4)\n",
    "    \n",
    "    i = 0\n",
    "    for v in normalized_out:\n",
    "        if v.norm() > 0:\n",
    "            i += 1\n",
    "        \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 개별 t에 대한 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for t in range(d.n_steps):\n",
    "    models.append(MyModel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 - training_model_1\n",
    "epochs = 500\n",
    "\n",
    "losses = training_model_4(epochs, grid_points, data1, d, models, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MyModel prediction - training_model_2 결과\n",
    "t_slider = widgets.IntSlider(value=0, min=1, max=d.n_steps, step=1, description='t')\n",
    "def update(t):\n",
    "    with torch.no_grad():\n",
    "        outputs = models[t-1](t)\n",
    "        normalized_out = normalize_vector_field(outputs)\n",
    "\n",
    "        # draw_vector_field(grid_points.cpu(), outputs.cpu(), lim=5, title_str=\"predicted vector field at t={}\".format(t))\n",
    "        draw_vector_field(grid_points.cpu(), normalized_out.cpu(), lim=5, title_str=\"predicted vector field at t={}\".format(t), scale=5)\n",
    "widgets.interact(update, t=t_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모든 t에 대해 Training - training_model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model\n",
    "m2 = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 - training_model_2\n",
    "epochs = 500\n",
    "\n",
    "all_losses = training_model_2(epochs, grid_points, data1, d, m2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, loss in enumerate(all_losses):\n",
    "    print(\"Final loss at t={}: {}\".format(t+1, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MyModel prediction - training_model_2 결과\n",
    "t_slider = widgets.IntSlider(value=0, min=1, max=d.n_steps, step=1, description='t')\n",
    "def update(t):\n",
    "    with torch.no_grad():\n",
    "        outputs = m2(t)\n",
    "        # normalized_out = normalize_vector_field(outputs)\n",
    "        \n",
    "        draw_vector_field(grid_points.cpu(), outputs.cpu(), lim=5, title_str=\"predicted vector field at t={}\".format(t))\n",
    "        # draw_vector_field(grid_points.cpu(), normalized_out.cpu(), title_str=\"predicted vector field at t={}\".format(t), scale=3)\n",
    "widgets.interact(update, t=t_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모든 t에 대해 Training - training_model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model\n",
    "m3 = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 - training_model_3\n",
    "epochs = 500\n",
    "\n",
    "final_loss = training_model_3(epochs, grid_points, data1, d, m3, device=device)\n",
    "print(\"final loss: {}\".format(final_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MyModel prediction - training_model_2 결과\n",
    "t_slider = widgets.IntSlider(value=0, min=1, max=d.n_steps, step=1, description='t')\n",
    "def update(t):\n",
    "    with torch.no_grad():\n",
    "        _,vec = make_vectors(d, data1.to(device), t)\n",
    "        outputs = make_vector_field(grid_points, data1, vec)\n",
    "        normalized_out = normalize_vector_field(outputs)\n",
    "\n",
    "        # draw_vector_field(grid_points.cpu(), outputs.cpu(), lim=5, title_str=\"predicted vector field at t={}\".format(t))\n",
    "        draw_vector_field(grid_points.cpu(), normalized_out.cpu(), lim=5, title_str=\"predicted vector field at t={}\".format(t), scale=5)\n",
    "widgets.interact(update, t=t_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MyModel prediction - training_model_2 결과\n",
    "t_slider = widgets.IntSlider(value=0, min=1, max=d.n_steps, step=1, description='t')\n",
    "def update(t):\n",
    "    with torch.no_grad():\n",
    "        outputs = m3(t)\n",
    "        normalized_out = normalize_vector_field(outputs)\n",
    "\n",
    "        # draw_vector_field(grid_points.cpu(), outputs.cpu(), lim=5, title_str=\"predicted vector field at t={}\".format(t))\n",
    "        draw_vector_field(grid_points.cpu(), normalized_out.cpu(), lim=5, title_str=\"predicted vector field at t={}\".format(t), scale=5)\n",
    "widgets.interact(update, t=t_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기타 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = './diffusive_flow.pth'\n",
    "# torch.save(m.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian data (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a Gaussian data\n",
    "dim = 2\n",
    "datanum = 500\n",
    "mean = np.array([4.5, 0])\n",
    "cov = np.array([[0, 2],[0, 2]])\n",
    "\n",
    "data2 = np.random.multivariate_normal(mean, cov, datanum)\n",
    "data2 = torch.from_numpy(data2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_data(data2.cpu(), title_str='Data2')\n",
    "lim = 5\n",
    "plt.xlim(-lim, lim)\n",
    "plt.ylim(-lim, lim)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model\n",
    "m4 = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "epochs = 500\n",
    "\n",
    "training_model_3(epochs, grid_points, data2, d, m4, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(epochs), losses)\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.show()\n",
    "\n",
    "# print(losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffused data (from t=0 to t=9) (비교용)\n",
    "eta = torch.randn_like(data2).to(device)\n",
    "x_curr = data2.to(device)\n",
    "# for t in range(n_steps):\n",
    "#     x_curr, v = make_vectors(d, x_curr, t)\n",
    "x_curr, v = make_vectors(d, x_curr, 1)\n",
    "\n",
    "vf = make_vector_field(grid_points, data2, v)\n",
    "\n",
    "# v = x_curr.to(device) - data2.to(device)\n",
    "# normalized_v = normalize_vector_field(v)\n",
    "\n",
    "draw_vector_field(grid_points.cpu(), vf.cpu(), title_str=\"diffused data - avg. vector field\")\n",
    "# draw_vector_field(data2.cpu(), normalized_v.cpu(), title_str=\"diffused data\")\n",
    "# draw_vector_field(data2.cpu(), v.cpu())\n",
    "i = 0\n",
    "for v in vf:\n",
    "    if v.norm() > 0:\n",
    "        i += 1\n",
    "    \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MyModel prediction - training_model_2 결과\n",
    "t_slider = widgets.IntSlider(value=0, min=0, max=d.n_steps-1, step=1, description='t')\n",
    "def update(t):\n",
    "    with torch.no_grad():\n",
    "        outputs = m4(t)\n",
    "        normalized_out = normalize_vector_field(outputs)\n",
    "\n",
    "        # draw_vector_field(grid_points.cpu(), outputs.cpu(), lim=8, title_str=\"predicted vector field at t={}\".format(t))\n",
    "        draw_vector_field(grid_points.cpu(), normalized_out.cpu(), title_str=\"predicted vector field at t={}\".format(t), scale=5)\n",
    "widgets.interact(update, t=t_slider)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 ('torch-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "652d9c878910970460809429ea4d514d2a6a5411db410063005e82113ebfc1c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
