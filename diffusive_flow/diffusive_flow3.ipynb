{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, embed_dim=64, hidden_dim=64, output_dim=2, t_range=500, t_step=20):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.t_step = t_step\n",
    "        \n",
    "        self.x_embedding = nn.Linear(2, embed_dim)\n",
    "        \n",
    "        self.t_embedding = nn.Sequential(\n",
    "            nn.Embedding(t_range, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embed_dim*2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, xT, t):\n",
    "        t_tensor = torch.full((xT.size(0),1), t*self.t_step)\n",
    "\n",
    "        embeded_xT = self.x_embedding(xT)\n",
    "        embeded_t = self.t_embedding(t_tensor).squeeze(1)\n",
    "        cat_embeded = torch.cat((embeded_xT, embeded_t), dim=1)\n",
    "\n",
    "        out = self.fc(cat_embeded)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffuse 관련 변수 및 함수 정의\n",
    "\n",
    "def make_beta_alpha(min_beta, max_beta, t_range, device=device):\n",
    "    betas = torch.linspace(min_beta, max_beta, t_range).to(device)\n",
    "    alphas = 1 - betas\n",
    "    alpha_bars = torch.tensor([torch.prod(alphas[:(i+1)]) for i in range(t_range)]).to(device)\n",
    "    return betas, alphas, alpha_bars\n",
    "\n",
    "def diffuse_x(x0, t, alpha_bars, eta=None, device=device):\n",
    "    if not isinstance(x0, torch.Tensor):\n",
    "        x0 = torch.tensor(x0).to(device)\n",
    "    else:\n",
    "        x0 = x0.to(device)\n",
    "        \n",
    "    n, d = x0.shape\n",
    "    a_bar = alpha_bars[t]\n",
    "\n",
    "    if eta is None:\n",
    "        eta = torch.randn(n, d).to(device)\n",
    "    \n",
    "    xT = a_bar.sqrt().view(-1,1) * x0 + (1 - a_bar).sqrt().view(-1,1) * eta\n",
    "\n",
    "    return xT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make vector field\n",
    "def vector_field(vectors, scale=0.5):\n",
    "    vf = vectors * scale\n",
    "    return vf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid 생성\n",
    "def make_grid(lim, n, device=device):\n",
    "    x = np.linspace(-lim, lim, n)\n",
    "    y = np.linspace(-lim, lim, n)\n",
    "    X, Y = np.meshgrid(x, y)   # 20x20, 20x20\n",
    "    X = X.reshape([-1,1])   # 20^2 x 1\n",
    "    Y = Y.reshape([-1,1])   # 20^2 x 1\n",
    "\n",
    "    grid_points = np.concatenate([X, Y], axis=1)\n",
    "    return torch.tensor(grid_points, device=device, dtype=torch.float32)\n",
    "\n",
    "grid_points = make_grid(5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_data(data, lim=5, title_str='Data', color='blue'):\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        data = data.cpu()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.scatter(data[:,0], data[:,1], label='data', c=color, alpha=1, s=5)\n",
    "    ax.set_xlim(-lim, lim)\n",
    "    ax.set_ylim(-lim, lim)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_title(title_str)\n",
    "    ax.grid(True)\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_vector_field(grid_points, vf, scale=5, color='blue', width=0.003, title='Vector Field'):\n",
    "    if isinstance(grid_points, torch.Tensor):\n",
    "        grid_points = grid_points.cpu().detach().numpy()\n",
    "    if isinstance(vf, torch.Tensor):\n",
    "        vf = vf.cpu().detach().numpy()\n",
    "        \n",
    "    X = grid_points[:, 0]\n",
    "    Y = grid_points[:, 1]\n",
    "    \n",
    "    U = vf[:, 0]\n",
    "    V = vf[:, 1]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.quiver(X, Y, U, V, scale=scale, color=color, width=width)\n",
    "    plt.xlabel('X')\n",
    "    plt.xlabel('Y')\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_data(grid_points, data, alpha_bars, eta=None, t_range=200, max_distance=0.5, device=device):\n",
    "    if not isinstance(data, torch.Tensor):\n",
    "        x0 = torch.tensor(data).to(device)\n",
    "    else:\n",
    "        x0 = data.to(device)\n",
    "\n",
    "    if eta is None:\n",
    "        eta = torch.randn_like(x0).to(device)\n",
    "\n",
    "    vector_fields = []\n",
    "    xTs = []\n",
    "\n",
    "    for t in range(t_range):\n",
    "        xT = diffuse_x(x0, t, alpha_bars, eta=eta)\n",
    "        xTs.append(xT.clone().detach().cpu().numpy())\n",
    "        \n",
    "        tree = cKDTree(x0.detach().cpu().numpy())\n",
    "\n",
    "        if isinstance(grid_points, torch.Tensor):\n",
    "            grid_points = grid_points.detach().cpu().numpy()\n",
    "\n",
    "        avg_vecs = np.zeros_like(grid_points)\n",
    "\n",
    "        for i, point in enumerate(grid_points):\n",
    "            indices = tree.query_ball_point(point, r=max_distance)\n",
    "            if len(indices) == 0:\n",
    "                avg_vecs[i] = np.array([0.0, 0.0])\n",
    "                continue\n",
    "            neighbor_vecs = xT[indices].cpu().numpy() - x0[indices].cpu().numpy()\n",
    "\n",
    "            avg_vec = neighbor_vecs.mean(axis=0)\n",
    "            avg_vecs[i] = avg_vec.copy()\n",
    "\n",
    "        vector_fields.append(avg_vecs.copy())\n",
    "        \n",
    "    \n",
    "    return xTs, vector_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sample_data_2d(mean, cov, datanum=200):\n",
    "    data = np.random.multivariate_normal(mean, cov, datanum)\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    return data.copy()\n",
    "\n",
    "# mean = np.array([0,0])\n",
    "# cov = np.array([[.01,.001], [.001,.01]])\n",
    "# data = torch.tensor(make_sample_data_2d(mean, cov, datanum))\n",
    "\n",
    "# lim = 5\n",
    "# fig = draw_data(data, lim)\n",
    "# display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_range = 100\n",
    "min_beta = 1e-4\n",
    "max_beta = 1e-2\n",
    "scale = 1000 / t_range\n",
    "betas, alphas, alpha_bars = make_beta_alpha(min_beta * scale, max_beta * scale, t_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diffuse 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanum = 500\n",
    "mean = np.array([0,0])\n",
    "cov = np.array([[.01,.001], [.001,.01]])\n",
    "data = torch.tensor(make_sample_data_2d(mean, cov, datanum)).to(device)\n",
    "xTs_diffused = [data.clone().detach().cpu().numpy()]\n",
    "\n",
    "eta = torch.randn_like(data).to(device)\n",
    "for t in range(t_range):\n",
    "    xT = diffuse_x(data, t, alpha_bars, eta=eta)\n",
    "    xTs_diffused.append(xT.clone().detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9746564c536a4146a9b2b429d1e01a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='t', max=99), Output()), _dom_classes=('widget-interact',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update(t)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_slider = widgets.IntSlider(value=0, min=0, max=t_range-1, step=1, description='t')\n",
    "def update(t):\n",
    "    with torch.no_grad():\n",
    "        fig = draw_data(xTs_diffused[t], 5, title_str=\"X_T at T = {}\".format(t))\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "        \n",
    "widgets.interact(update, t=t_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_step = 10\n",
    "model = MyModel(embed_dim=64, hidden_dim=128, output_dim=2, t_range=t_range, t_step=t_step).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m eta \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(data)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m xT \u001b[38;5;241m=\u001b[39m diffuse_x(data, t, alpha_bars, eta\u001b[38;5;241m=\u001b[39meta)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 22\u001b[0m ouput \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# eta_for_obj = (1/(1-alpha_bars[t])) * (xT - alpha_bars[t] * data)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(ouput\u001b[38;5;241m.\u001b[39mto(device), eta\u001b[38;5;241m.\u001b[39mto(device))\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 32\u001b[0m, in \u001b[0;36mMyModel.forward\u001b[0;34m(self, xT, t)\u001b[0m\n\u001b[1;32m     29\u001b[0m t_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((xT\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),\u001b[38;5;241m1\u001b[39m), t\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_step)\n\u001b[1;32m     31\u001b[0m embeded_xT \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_embedding(xT)\n\u001b[0;32m---> 32\u001b[0m embeded_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_tensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     33\u001b[0m cat_embeded \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((embeded_xT, embeded_t), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     35\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(cat_embeded)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.12/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    164\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    165\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.12/site-packages/torch/nn/functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2258\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2259\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2260\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2261\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2264\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "epochs = 1_000\n",
    "learning_rate = 0.1\n",
    "losses = []\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "for eopch in tqdm(range(epochs), desc='Training Epochs'):\n",
    "    shuffle_t = np.random.permutation(t_range)\n",
    "    for t in shuffle_t:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        datanum = 500\n",
    "        mean = np.array([0, 0])\n",
    "        cov = np.array([[.01,.001], [.001,.01]])\n",
    "        data = torch.tensor(make_sample_data_2d(mean, cov, datanum)).to(device)\n",
    "\n",
    "        # t = torch.randint(0, t_range, (1,)).item()\n",
    "\n",
    "        eta = torch.randn_like(data).to(device)\n",
    "        xT = diffuse_x(data, t, alpha_bars, eta=eta).to(device)\n",
    "\n",
    "        ouput = model(xT, t)\n",
    "\n",
    "        # eta_for_obj = (1/(1-alpha_bars[t])) * (xT - alpha_bars[t] * data)\n",
    "        loss = criterion(ouput.to(device), eta.to(device))\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # loss = criterion(eta_for_obj.to(device), ouput.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final loss: {}\".format( losses[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습된 model로 reverse process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = np.array([0, 0])\n",
    "# cov = np.array([[.1, 0.01], [0.01, .1]])\n",
    "# data = torch.tensor(make_sample_data_2d(mean, cov, 300))\n",
    "data = torch.empty((datanum, 2)).normal_()\n",
    "\n",
    "display(draw_data(data, 6))\n",
    "\n",
    "xTs = [data.clone().detach().cpu().numpy()]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for t in range(t_range-1, -1, -1):\n",
    "    xT_1 = (1 / alphas[t].sqrt())*(data - (betas[t] / (1-alpha_bars[t]).sqrt()) * model(data, t))\n",
    "\n",
    "    xTs.append(xT_1.clone().detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_slider = widgets.IntSlider(value=t_range-1, min=0, max=t_range-1, step=1, description='t')\n",
    "def update(t):\n",
    "    with torch.no_grad():\n",
    "        fig = draw_data(xTs[t], 3, title_str=\"X_T at T = {}\".format(t))\n",
    "        display(fig)\n",
    "        \n",
    "widgets.interact(update, t=t_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mean = np.array([0, 0])\n",
    "# # cov = np.array([[3, 0.3], [0.3, 3]])\n",
    "# data = torch.randn((datanum,2))\n",
    "\n",
    "# # draw_data(data, 6)\n",
    "\n",
    "# xTs = [data.clone().detach().cpu().numpy()]\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "# for t in range(t_range):\n",
    "#     eta = model(data, t)\n",
    "#     xT = diffuse_x(data, t, alpha_bars, eta=eta)\n",
    "\n",
    "#     xTs.append(xT.clone().detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_slider = widgets.IntSlider(value=0, min=0, max=t_range-1, step=1, description='t')\n",
    "# def update(t):\n",
    "#     with torch.no_grad():\n",
    "#         fig = draw_data(xTs[t], 3, title_str=\"X_T at T = {}\".format(t))\n",
    "#         display(fig)\n",
    "        \n",
    "# widgets.interact(update, t=t_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xTs, training_data = make_training_data(grid_points, data, alpha_bars, eta=eta, t_range=t_range)\n",
    "# for i, td in enumerate(training_data):\n",
    "#     training_data[i] = vector_field(td, scale=.3)\n",
    "\n",
    "# # training data 저장\n",
    "# np.savez('xTs_and_vfs.npz', xTs=xTs, training_data=training_data)\n",
    "\n",
    "# # training data 로드\n",
    "# loaded = np.load('xTs_and_vfs.npz')\n",
    "# xTs = loaded['xTs']\n",
    "# training_data = loaded['training_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_data(data)\n",
    "# draw_data(xTs[499])\n",
    "# draw_vector_field(grid_points, training_data[499])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 ('torch-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "652d9c878910970460809429ea4d514d2a6a5411db410063005e82113ebfc1c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
